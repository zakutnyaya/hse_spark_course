{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MapReduce на mrjob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mrjob это библиотека для Python, которая позволяет создавать MapReduce jobs. \n",
    "\n",
    "Документация по MRJob: [https://mrjob.readthedocs.io/en/latest/](https://mrjob.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем файл из MapReduce(bash) `fruits.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mrjob\n",
      "  Downloading mrjob-0.7.4-py2.py3-none-any.whl (439 kB)\n",
      "\u001b[K     |████████████████████████████████| 439 kB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=3.10 in /Users/pro/anaconda/lib/python3.6/site-packages (from mrjob) (3.12)\n",
      "Installing collected packages: mrjob\n",
      "Successfully installed mrjob-0.7.4\n",
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/Users/pro/anaconda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install mrjob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 pro  staff    59B  1 мар 10:25 fruits.txt\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls -lh fruits.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим файл `word_count.py` с помощью magic в Jupyter Notebook `%%file`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting word_count.py\n"
     ]
    }
   ],
   "source": [
    "%%file word_count.py\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "class MRWordFrequencyCount(MRJob):\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        # когда используем yield, функция не останавливается в отличие от return \n",
    "        # yield работает как генератор \n",
    "        yield \"chars\", len(line)\n",
    "        yield \"words\", len(line.split())\n",
    "        yield \"lines\", 1\n",
    "    # на каждый ключ суммируем\n",
    "    def reducer(self, key, values):\n",
    "        yield key, sum(values)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRWordFrequencyCount.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple banana\r\n",
      "peach orange peach peach\r\n",
      "pineapple peach apple"
     ]
    }
   ],
   "source": [
    "!cat fruits.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for inline runner\n",
      "Creating temp directory /var/folders/b1/01k3115d6txccqktf5wpvqdr0000gn/T/word_count.pro.20210301.093022.610760\n",
      "Running step 1 of 1...\n",
      "reading from STDIN\n",
      "job output is in /var/folders/b1/01k3115d6txccqktf5wpvqdr0000gn/T/word_count.pro.20210301.093022.610760/output\n",
      "Streaming final output from /var/folders/b1/01k3115d6txccqktf5wpvqdr0000gn/T/word_count.pro.20210301.093022.610760/output...\n",
      "\"words\"\t9\n",
      "\"lines\"\t3\n",
      "\"chars\"\t57\n",
      "Removing temp directory /var/folders/b1/01k3115d6txccqktf5wpvqdr0000gn/T/word_count.pro.20210301.093022.610760...\n"
     ]
    }
   ],
   "source": [
    "!cat fruits.txt | python word_count.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем определит кол-во мапперов и редьюсеров, на пример $10$ мапперов и $3$ редьюсеров. (игрушечный пример)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"words\"\t12\n",
      "\"lines\"\t6\n",
      "\"chars\"\t170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for inline runner\n",
      "Creating temp directory /var/folders/b1/01k3115d6txccqktf5wpvqdr0000gn/T/word_count.pro.20210303.184935.772454\n",
      "Running step 1 of 1...\n",
      "reading from STDIN\n",
      "job output is in /var/folders/b1/01k3115d6txccqktf5wpvqdr0000gn/T/word_count.pro.20210303.184935.772454/output\n",
      "Streaming final output from /var/folders/b1/01k3115d6txccqktf5wpvqdr0000gn/T/word_count.pro.20210303.184935.772454/output...\n",
      "Removing temp directory /var/folders/b1/01k3115d6txccqktf5wpvqdr0000gn/T/word_count.pro.20210303.184935.772454...\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# запускаем локально\n",
    "DATAFILE=fruits.txt\n",
    "STREAMING_JAR=/opt/cloudera/parcels/CDH/lib/hadoop-mapreduce/hadoop-streaming.jar\n",
    "N=10\n",
    "\n",
    "# N map tasks\n",
    "# запускаем локально (в питоне)\n",
    "python word_count.py\\\n",
    "    # количество маперов\n",
    "    --jobconf mapreduce.job.maps=$N\\\n",
    "    # количество редьюсеров\n",
    "    --jobconf mapreduce.job.reduces=3\\\n",
    "    -r hadoop\\\n",
    "    --hadoop-streaming-jar $STREAMING_JAR\\\n",
    "    $DATAFILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем эксперименты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "START=$(date +%s);\n",
    "\n",
    "DATAFILE=# файл с большим набором данных\n",
    "STREAMING_JAR=/opt/cloudera/parcels/CDH/lib/hadoop-mapreduce/hadoop-streaming.jar\n",
    "N=4 # кол-во мапперов\n",
    "\n",
    "# N map tasks\n",
    "python word_count.py\\\n",
    "    --jobconf mapreduce.job.maps=$N\\\n",
    "    --jobconf mapreduce.job.reduces=3\\\n",
    "    -r hadoop --hadoop-streaming-jar $STREAMING_JAR\\\n",
    "    $DATAFILE\n",
    "    \n",
    "2>/dev/null\n",
    "\n",
    "END=$(date +%s);\n",
    "echo $((END-START)) | awk '{print \"Duration: \"int($1/60)\":\"int($1%60)}'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
